# -*- coding: utf-8 -*-
"""Copia di MLDL_Lab01_Ex02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sGIbTiLsbcWaH83sdYboBIrmfEMGJ4HD

### PyTorch DataLoader Exercises

Welcome to the PyTorchDataLoader exercise template notebook.

There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.

> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can.
"""

# Import necessary libraries
import os
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import matplotlib.pyplot as plt
import requests
from zipfile import ZipFile
from io import BytesIO
import numpy as np

# Define the path to the dataset
dataset_path = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'  # Replace with the path to your dataset

# Send a GET request to the URL
response = requests.get(dataset_path)
# Check if the request was successful
if response.status_code == 200:
    # Open the downloaded bytes and extract them
    with ZipFile(BytesIO(response.content)) as zip_file:
        zip_file.extractall('/dataset')
    print('Download and extraction complete!')

# Define transformations for the dataset
#
transform = transforms.Compose([
    # 1. PREPARAZIONE INIZIALE
    transforms.Resize((256, 256)),

    # 2. DATA AUGMENTATION
    transforms.RandomHorizontalFlip(p=0.5), # Flippa casualmente
    transforms.RandomCrop(224),             # Ritaglia casualmente (usando la dimensione finale del modello, es. 224x224)
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Variazioni di colore

    # 3. PASSAGGI OBBLIGATORI PER PYTORCH
    transforms.ToTensor(), # <-- ESSENZIALE: Converte l'immagine (PIL/NumPy) in un Tensor

    # 4. NORMALIZZAZIONE
    # Questi sono i valori standard per i modelli pre-addestrati su ImageNetà
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load the dataset
tiny_imagenet_dataset_train = ImageFolder(root='/dataset/tiny-imagenet-200/train', transform=transform)
tiny_imagenet_dataset_test = ImageFolder(root='/dataset/tiny-imagenet-200/test', transform=transform)

# Create a DataLoader
dataloader_train = DataLoader(dataset= tiny_imagenet_dataset_train, batch_size=64,shuffle = True, num_workers=1)
dataloader_test = DataLoader(dataset= tiny_imagenet_dataset_test, batch_size=64,shuffle = False, num_workers=1)

# Determine the number of classes and samples
num_classes = len(tiny_imagenet_dataset_train.classes)
num_samples = len(tiny_imagenet_dataset_train)

print(f'Number of classes: {num_classes}')
print(f'Number of samples: {num_samples}')

# Function to denormalize image for visualization
def denormalize(image):
    image = image.to('cpu').numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image = image * std + mean
    image = np.clip(image, 0, 1)
    return image

# Visualize one example for each class for 10 classes
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
classes_sampled = []
found_classes = 0
image_for_classes = {}

# my idea: prendo nel ciclo for, controllo che classe è
# se è gia in classe sampled allora skip
# se no inserirsco e vedo di trovarle tutte
# ho numero di classi quindi se le trovo tutte esco

for i, (inputs, classes) in enumerate(dataloader_train): # itera per ogni batch
    for (image,classe) in zip(inputs,classes): # cosi prendo tutte le immagini
        # Estrai l'indice della classe come numero Python
        classe_idx = classe.item()

        if classe_idx not in classes_sampled:
          #non l'avevo ancora trovata una di questa classe
          classes_sampled.append(classe) # aggiungo classe
          found_classes+=1
          image_for_classes[classe_idx] = image

        if found_classes == num_classes:
          break  # esco dal ciclo for
    if found_classes == num_classes:
        break  # esco dal ciclo for


#VISUALIZZAZIONE BY CHATTTTTTT   ------------------

# Ottieni gli indici delle classi trovate e i loro Tensor immagine
class_indices = list(image_for_classes.keys())
sample_images = list(image_for_classes.values())

fig, axes = plt.subplots(2, 5, figsize=(15, 6))
axes = axes.flatten() # Rendi gli assi 1D per una facile iterazione

# Mappa per convertire gli indici di classe (es. 0, 1, 2) ai nomi reali
# Assumendo che il tuo dataset sia accessibile:
class_names = dataloader_train.dataset.classes

for idx, ax in enumerate(axes):
    if idx < len(sample_images):
        image = sample_images[idx]
        class_idx = class_indices[idx]

        # A. De-normalizzazione e conversione in NumPy
        # La tua immagine è normalizzata, devi riportarla in un range visualizzabile
        # (Questo è un passaggio cruciale che manca nella tua idea iniziale)

        # Parametri di Normalizzazione (da torchvision.transforms.Normalize)
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])

        # Sposta l'immagine da Tensor PyTorch a Numpy
        img_np = image.numpy().transpose((1, 2, 0)) # Cambia da (C, H, W) a (H, W, C)

        # De-normalizza: img = img * std + mean
        img_np = img_np * std + mean

        # Clipping per gestire valori fuori range [0, 1] dovuti a precisione o errori
        img_np = np.clip(img_np, 0, 1)

        # B. Plotting
        ax.imshow(img_np)
        ax.set_title(f"Classe: {class_names[class_idx]} ({class_idx})")
        ax.axis('off')

plt.tight_layout()
plt.show()

